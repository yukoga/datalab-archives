{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About this notebook\n",
    "Besides CloudML's built-in preprocessing features, sometimes you want to preprocess your data with your own pipeline. This sample includes a custom preprocessing pipeline, which depends on DataFlow and a pretrained image model to preprocess JPEG images. It extracts features and turn them into a format that is accepted by CloudML service.\n",
    "\n",
    "Since Dataflow currently has a limitation that dependency python files are not copied to workers, we have to invoke the python file with a bash command. You can view the code by running the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load preprocess.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image identification sample uses custom preprocessing. It calls DataFlow pipeline to extract features out of JPEG images, into data format that is accepted by Cloud ML.\n",
    "\n",
    "There a a few libraries that preprocessor depends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "apt-get install -y libjpeg-dev python-imaging\n",
    "pip install Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Source Data\n",
    "Create Storage bucket to hold training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some code to determine a unique bucket name for the purposes of the sample\n",
    "from gcp.context import Context\n",
    "\n",
    "CLOUD_PROJECT = Context.default().project_id\n",
    "ml_bucket_name = CLOUD_PROJECT + '-mldata'\n",
    "ml_bucket_path = 'gs://' + ml_bucket_name\n",
    "\n",
    "INPUT_DIR = ml_bucket_path + '/sampledata/ml/image/input/'\n",
    "OUTPUT_DIR = ml_bucket_path + '/sampledata/ml/image/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%storage create --bucket $ml_bucket_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy image source data to your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$INPUT_DIR\"\n",
    "gsutil -m -q cp -r gs://cloud-datalab/sampledata/ml/image/* $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is running, you can go to Developer Console and watch the DataFlow job progress.\n",
    "Please ignore an Error output \"This account is not whitelisted to run Python-based pipelines...\". This warning message shows even if the job is completed successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:\n",
      "*************************************************************\n",
      "This account is not whitelisted to run Python-based pipelines using the Google Cloud Dataflow service. Make sure that your project is whitelisted before submitting your job. \n",
      "Please see documentation for getting more information on getting your project whitelisted.\n",
      "*************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$INPUT_DIR\" \"$OUTPUT_DIR\" \"$CLOUD_PROJECT\"\n",
    "python preprocess.py \\\n",
    "  --input_data_location $1\\\n",
    "  --output $2 \\\n",
    "  --job_name cloud-ml-sample-image-classification \\\n",
    "  --project $3 \\\n",
    "  --staging_location \"$2/staging\" \\\n",
    "  --temp_location \"$2/temp\" \\\n",
    "  --runner BlockingDataflowPipelineRunner \\\n",
    "  --num_workers 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's browse the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/:\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.test.json-00000-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.test.json-00001-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.test.json-00002-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.test.json-00003-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.test.json-00004-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.test.json-00005-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.test.json-00006-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.test.json-00007-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.test.json-00008-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.test.json-00009-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.train.json-00000-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.train.json-00001-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.train.json-00002-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.train.json-00003-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.train.json-00004-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.train.json-00005-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.train.json-00006-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.train.json-00007-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.train.json-00008-of-00010\n",
      "gs://cloud-ml-users-mldata/sampledata/ml/image/output/data/data.train.json-00009-of-00010\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$OUTPUT_DIR\"\n",
    "gsutil list -r \"$1data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
