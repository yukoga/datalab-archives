{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage API sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gcp\n",
    "import gcp.storage as storage\n",
    "from gcp.context import Context\n",
    "import random\n",
    "import pandas as pd\n",
    "from StringIO import StringIO\n",
    "project = Context.default().project_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bucket_name = \"yukoga-kaggle\"\n",
    "bucket_path = \"gs://\" + bucket_name\n",
    "test_sample_size = 1000\n",
    "train_sample_size = 1000\n",
    "sample_submission_sample_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921806060722-compute@developer.gserviceaccount.com"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "curl --silent -H \"Metadata-Flavor: Google\" http://metadata/computeMetadata/v1/instance/service-accounts/default/email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get skiprows for pandas.DataFrame\n",
    "def get_skiprows(sample_size, num_records):\n",
    "  return sorted(random.sample(range(1,num_records),num_records - sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test data\n",
    "%storage read --object \"gs://yukoga-kaggle/facebook-checkin/test.csv\" --variable tmp_table\n",
    "num_records = len(tmp_table.split('\\n'))\n",
    "test = pd.read_csv(StringIO(tmp_table), skiprows=get_skiprows(test_sample_size, num_records))\n",
    "del tmp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2846</td>\n",
       "      <td>6.5062</td>\n",
       "      <td>7.8125</td>\n",
       "      <td>163</td>\n",
       "      <td>902890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3545</td>\n",
       "      <td>4.0610</td>\n",
       "      <td>2.3397</td>\n",
       "      <td>70</td>\n",
       "      <td>947237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16838</td>\n",
       "      <td>4.6995</td>\n",
       "      <td>2.8846</td>\n",
       "      <td>65</td>\n",
       "      <td>790867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26387</td>\n",
       "      <td>8.6525</td>\n",
       "      <td>0.5807</td>\n",
       "      <td>65</td>\n",
       "      <td>841739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31764</td>\n",
       "      <td>6.5354</td>\n",
       "      <td>7.0423</td>\n",
       "      <td>61</td>\n",
       "      <td>885250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id       x       y  accuracy    time\n",
       "0    2846  6.5062  7.8125       163  902890\n",
       "1    3545  4.0610  2.3397        70  947237\n",
       "2   16838  4.6995  2.8846        65  790867\n",
       "3   26387  8.6525  0.5807        65  841739\n",
       "4   31764  6.5354  7.0423        61  885250"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get sampled records from cloud storage\n",
    "def read_sampled_lines(item, sample_size):\n",
    "  \"\"\"Reads the content of this item as text, and return a list of lines up to some max.\n",
    "\n",
    "  Args:\n",
    "    item: item object from Google Cloud Storage.\n",
    "    start_offset_line: an index indicates start offset records within a item.\n",
    "    max_lines: max number of lines to return. If None, return all lines.\n",
    "  Returns:\n",
    "    The text content of the item as a list of lines.\n",
    "  Raises:\n",
    "    Exception if there was an error requesting the item's content.\n",
    "  \"\"\"\n",
    "  def read_specific_lines(item, offset, num_records):\n",
    "    start_to_read = 100 * (0 if offset is None else offset)\n",
    "    max_to_read = item.metadata.size\n",
    "    num_records = max_to_read if num_records is None else num_records\n",
    "    bytes_to_read = min(100 * num_records, item.metadata.size)\n",
    "    \n",
    "    lines = []\n",
    "    while True:\n",
    "      content = item.read_from(start_offset=start_to_read, bytes_to_read)\n",
    "      lines = content.split('\\n')\n",
    "      if len(lines) > num_records or bytes_to_read >= max_to_read:\n",
    "        break\n",
    "      bytes_to_read = min_lines or bytes_to_read >= max_to_read:\n",
    "\n",
    "    del lines[-1]\n",
    "    return lines[0:num_records]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expedia/ : 0\n",
      "expedia/destinations.csv : 138159416\n",
      "expedia/sample_submission.csv : 31756066\n",
      "expedia/test.csv : 276554476\n",
      "expedia/train.csv : 4070445781\n",
      "facebook-checkin/sample_submission.csv : 351785336\n",
      "facebook-checkin/test.csv : 273911533\n",
      "facebook-checkin/train.csv : 1268930440\n",
      "Help on method read_lines in module gcp.storage._item:\n",
      "\n",
      "read_lines(self, max_lines=None) method of gcp.storage._item.Item instance\n",
      "    Reads the content of this item as text, and return a list of lines up to some max.\n",
      "    \n",
      "    Args:\n",
      "      max_lines: max number of lines to return. If None, return all lines.\n",
      "    Returns:\n",
      "      The text content of the item as a list of lines.\n",
      "    Raises:\n",
      "      Exception if there was an error requesting the item's content.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mybucket = storage.Bucket(bucket_name)\n",
    "for item in mybucket.items():\n",
    "  print item.metadata.name + \" : \" + str(item.metadata.size)\n",
    "  \n",
    "help(item.read_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  def object_download(self, bucket, key, start_offset=0, byte_count=None):\n",
      "    \"\"\"Reads the contents of an object as text.\n",
      "\n",
      "    Args:\n",
      "      bucket: the name of the bucket containing the object.\n",
      "      key: the key of the object to be read.\n",
      "      start_offset: the start offset of bytes to read.\n",
      "      byte_count: the number of bytes to read. If None, it reads to the end.\n",
      "    Returns:\n",
      "      The text content within the object.\n",
      "    Raises:\n",
      "      Exception if the object could not be read from.\n",
      "    \"\"\"\n",
      "    args = {'alt': 'media'}\n",
      "    headers = {}\n",
      "    if start_offset > 0 or byte_count is not None:\n",
      "      header = 'bytes=%d-' % start_offset\n",
      "      if byte_count is not None:\n",
      "        header += '%d' % byte_count\n",
      "      headers['Range'] = header\n",
      "    url = Api._DOWNLOAD_ENDPOINT + (Api._OBJECT_PATH % (bucket, Api._escape_key(key)))\n",
      "    return gcp._util.Http.request(url, args=args, headers=headers,\n",
      "        credentials=self._credentials, raw_response=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print inspect.getsource(item._api.object_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  def read_from(self, start_offset=0, byte_count=None):\n",
      "    \"\"\"Reads the content of this item as text.\n",
      "\n",
      "    Args:\n",
      "      start_offset: the start offset of bytes to read.\n",
      "      byte_count: the number of bytes to read. If None, it reads to the end.\n",
      "    Returns:\n",
      "      The text content within the item.\n",
      "    Raises:\n",
      "      Exception if there was an error requesting the item's content.\n",
      "    \"\"\"\n",
      "    try:\n",
      "      return self._api.object_download(self._bucket, self._key,\n",
      "                                       start_offset=start_offset, byte_count=byte_count)\n",
      "    except Exception as e:\n",
      "      raise e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print inspect.getsource(item.read_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  def read_lines(self, max_lines=None):\n",
      "    \"\"\"Reads the content of this item as text, and return a list of lines up to some max.\n",
      "\n",
      "    Args:\n",
      "      max_lines: max number of lines to return. If None, return all lines.\n",
      "    Returns:\n",
      "      The text content of the item as a list of lines.\n",
      "    Raises:\n",
      "      Exception if there was an error requesting the item's content.\n",
      "    \"\"\"\n",
      "    if max_lines is None:\n",
      "      return self.read_from().split('\\n')\n",
      "\n",
      "    max_to_read = self.metadata.size\n",
      "    bytes_to_read = min(100 * max_lines, self.metadata.size)\n",
      "    lines = []\n",
      "    while True:\n",
      "      content = self.read_from(byte_count=bytes_to_read)\n",
      "\n",
      "      lines = content.split('\\n')\n",
      "      if len(lines) > max_lines or bytes_to_read >= max_to_read:\n",
      "        break\n",
      "      # try 10 times more bytes or max\n",
      "      bytes_to_read = min(bytes_to_read * 10, max_to_read)\n",
      "\n",
      "    # remove the partial line at last\n",
      "    del lines[-1]\n",
      "    return lines[0:max_lines]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print inspect.getsource(item.read_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  @staticmethod\n",
      "  def request(url, args=None, data=None, headers=None, method=None,\n",
      "              credentials=None, raw_response=False, stats=None):\n",
      "    \"\"\"Issues HTTP requests.\n",
      "\n",
      "    Args:\n",
      "      url: the URL to request.\n",
      "      args: optional query string arguments.\n",
      "      data: optional data to be sent within the request.\n",
      "      headers: optional headers to include in the request.\n",
      "      method: optional HTTP method to use. If unspecified this is inferred\n",
      "          (GET or POST) based on the existence of request data.\n",
      "      credentials: optional set of credentials to authorize the request.\n",
      "      raw_response: whether the raw response content should be returned as-is.\n",
      "      stats: an optional dictionary that, if provided, will be populated with some\n",
      "          useful info about the request, like 'duration' in seconds and 'data_size' in\n",
      "          bytes. These may be useful optimizing the access to rate-limited APIs.\n",
      "    Returns:\n",
      "      The parsed response object.\n",
      "    Raises:\n",
      "      Exception when the HTTP request fails or the response cannot be processed.\n",
      "    \"\"\"\n",
      "    if headers is None:\n",
      "      headers = {}\n",
      "\n",
      "    headers['user-agent'] = 'GoogleCloudDataLab/1.0'\n",
      "    # Add querystring to the URL if there are any arguments.\n",
      "    if args is not None:\n",
      "      qs = urllib.urlencode(args)\n",
      "      url = url + '?' + qs\n",
      "\n",
      "    # Setup method to POST if unspecified, and appropriate request headers\n",
      "    # if there is data to be sent within the request.\n",
      "    if data is not None:\n",
      "      if method is None:\n",
      "        method = 'POST'\n",
      "\n",
      "      if data != '':\n",
      "        # If there is a content type specified, use it (and the data) as-is.\n",
      "        # Otherwise, assume JSON, and serialize the data object.\n",
      "        if 'Content-Type' not in headers:\n",
      "          data = json.dumps(data)\n",
      "          headers['Content-Type'] = 'application/json'\n",
      "      headers['Content-Length'] = str(len(data))\n",
      "    else:\n",
      "      if method == 'POST':\n",
      "        headers['Content-Length'] = '0'\n",
      "\n",
      "    # If the method is still unset, i.e. it was unspecified, and there\n",
      "    # was no data to be POSTed, then default to GET request.\n",
      "    if method is None:\n",
      "      method = 'GET'\n",
      "\n",
      "    # Create an Http object to issue requests. Associate the credentials\n",
      "    # with it if specified to perform authorization.\n",
      "    #\n",
      "    # TODO(nikhilko):\n",
      "    # SSL cert validation seemingly fails, and workarounds are not amenable\n",
      "    # to implementing in library code. So configure the Http object to skip\n",
      "    # doing so, in the interim.\n",
      "    http = httplib2.Http()\n",
      "    http.disable_ssl_certificate_validation = True\n",
      "    if credentials is not None:\n",
      "      http = credentials.authorize(http)\n",
      "    if stats is not None:\n",
      "      stats['duration'] = datetime.datetime.utcnow()\n",
      "\n",
      "    response = None\n",
      "    try:\n",
      "      response, content = http.request(url,\n",
      "                                       method=method,\n",
      "                                       body=data,\n",
      "                                       headers=headers)\n",
      "      if 200 <= response.status < 300:\n",
      "        if raw_response:\n",
      "          return content\n",
      "        return json.loads(content)\n",
      "      else:\n",
      "        raise RequestException(response.status, content)\n",
      "    except ValueError:\n",
      "      raise Exception('Failed to process HTTP response.')\n",
      "    except httplib2.HttpLib2Error:\n",
      "      raise Exception('Failed to send HTTP request.')\n",
      "    finally:\n",
      "      if stats is not None:\n",
      "        stats['data_size'] = len(data)\n",
      "        stats['status'] = response.status\n",
      "        stats['duration'] = (datetime.datetime.utcnow() - stats['duration']).total_seconds()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print inspect.getsource(gcp._util.Http.request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test data\n",
    "%storage read --object \"gs://yukoga-kaggle/facebook-checkin/test.csv\" --variable tmp_table\n",
    "num_records = len(tmp_table.split('\\n'))\n",
    "test = pd.read_csv(StringIO(tmp_table), skiprows=get_skiprows(test_sample_size, num_records))\n",
    "del tmp_table\n",
    "\n",
    "# sample submission data\n",
    "%storage read --object \"gs://yukoga-kaggle/facebook-checkin/sample_submission.csv\" --variable tmp_table\n",
    "num_records = len(tmp_table.split('\\n'))\n",
    "sample_submission = pd.read_csv(StringIO(tmp_table), skiprows=get_skiprows(sample_submission_sample_size, num_records))\n",
    "del tmp_table\n",
    "\n",
    "# train data\n",
    "%storage read --object \"gs://yukoga-kaggle/facebook-checkin/train.csv\" --variable tmp_table\n",
    "num_records = len(tmp_table.split('\\n'))\n",
    "train = pd.read_csv(StringIO(tmp_table), skiprows=get_skiprows(train_sample_size, num_records))\n",
    "del tmp_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix. tips for related python program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random sampling from list object\n",
    "```python\n",
    "mylist = [1,2,3,4,5,6,7,8,9,10]\n",
    "for idx, val in enumerate(mylist):\n",
    "  print \"{0} : {1}\".format(idx, val)\n",
    "print \"================\"\n",
    "for idx, val in enumerate(random.sample(mylist, 3)):\n",
    "  print \"{0} : {1}\".format(idx, val)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [load csv from google cloud storage to pandas.DataFrame on Google Datalab](http://stackoverflow.com/questions/37990467/how-can-i-load-my-csv-from-google-datalab-to-a-pandas-data-frame)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from StringIO import StringIO\n",
    "\n",
    "# Read csv file from GCS into a variable\n",
    "%storage read --object gs://cloud-datalab-samples/cars.csv --variable cars\n",
    "\n",
    "# Store in a pandas dataframe\n",
    "df = pd.read_csv(StringIO(cars))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Read a small random sample from a big CSV file into a Python data frame](http://stackoverflow.com/questions/22258491/read-a-small-random-sample-from-a-big-csv-file-into-a-python-data-frame)\n",
    "Assuming no header in the CSV file:\n",
    "\n",
    "```python\n",
    "import pandas\n",
    "import random\n",
    "\n",
    "n = 1000000 #number of records in file\n",
    "s = 10000 #desired sample size\n",
    "filename = \"data.txt\"\n",
    "skip = sorted(random.sample(xrange(n),n-s))\n",
    "df = pandas.read_csv(filename, skiprows=skip)\n",
    "```  \n",
    "\n",
    "would be better if read_csv had a keeprows, or if skiprows took a callback func instead of a list.\n",
    "\n",
    "With header and unknown file length:\n",
    "\n",
    "```python  \n",
    "import pandas\n",
    "import random\n",
    "\n",
    "filename = \"data.txt\"\n",
    "n = sum(1 for line in open(filename)) - 1 #number of records in file (excludes header)\n",
    "s = 10000 #desired sample size\n",
    "skip = sorted(random.sample(xrange(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "df = pandas.read_csv(filename, skiprows=skip)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample code.\n",
    "```python \n",
    "ns = locals()\n",
    "for item in mybucket.items(prefix='facebook-checkin/', delimiter='/'):\n",
    "  file_name = item.uri.split('/')[4]\n",
    "  data_name = file_name.split('.')[0]\n",
    "  %storage read --object $item.uri --variable tmp_table\n",
    "  num_records = len(tmp_table.split('\\n'))\n",
    "  sample_size = ns[data_name + \"_sample_size\"]\n",
    "  ns[data_name] = pd.read_csv(StringIO(tmp_table), \n",
    "                              skiprows=get_skiprows(sample_size, num_records))\n",
    "  del tmp_table\n",
    "  print file_name + \" : \" + str(num_records) + \" records.\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
